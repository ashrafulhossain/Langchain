{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KnowledgeAgent Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STA\\AppData\\Local\\Temp\\ipykernel_8964\\1400954758.py:28: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"deepseek-r1\")\n",
      "C:\\Users\\STA\\AppData\\Local\\Temp\\ipykernel_8964\\1400954758.py:59: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n",
      "C:\\Users\\STA\\AppData\\Local\\Temp\\ipykernel_8964\\1400954758.py:73: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent.run(query)  # Pass only the query string, not a dictionary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "LLM Output: <think>\n",
      "Okay, so I need to figure out what deep learning is. Hmm, I've heard the term before in tech and machine learning contexts, but I'm not entirely sure about the details. Let me start by breaking down the word itself. \"Deep\" usually implies something complex or multi-layered, and \"learning\" suggests some kind of training or process.\n",
      "\n",
      "I remember that deep learning is a subset of machine learning, which is part of artificial intelligence. So maybe it's a type of AI that uses algorithms inspired by neural networks. Neural networks in the human brain have layers—like neurons connected in multiple layers—and perhaps deep learning refers to having many such layers in machines as well.\n",
      "\n",
      "Wait, I think \"deep\" here refers to having several layers of neurons or artificial neurons. Traditional machine learning models might use a few layers, but deep learning uses many more, allowing them to learn more complex patterns from data. So maybe it's about using these multi-layered neural networks for tasks like image recognition or natural language processing.\n",
      "\n",
      "Let me think of examples where deep learning is applied. I've heard terms like convolutional neural networks (CNNs) used in image analysis and recurrent neural networks (RNNs) for sequence data like text. These seem to be types of deep learning models because they have multiple layers.\n",
      "\n",
      "So, putting it together: deep learning involves training artificial neural networks with many layers to learn hierarchical representations of data. This allows the model to capture complex patterns and perform tasks that are difficult with traditional machine learning approaches.\n",
      "\n",
      "I should also consider the process involved in deep learning. It typically requires a lot of data, computational power because each layer processes information, and algorithms like backpropagation to adjust weights based on errors. The result is systems that can automate decision-making or pattern recognition beyond what's possible with simpler models.\n",
      "\n",
      "Wait, but I'm not entirely clear on why having multiple layers is crucial. Does it help in learning more abstract features? For instance, in image classification, the first layer might detect edges, the next layer shapes, then textures, and so on, up to recognizing objects. So each layer builds upon the previous one's features.\n",
      "\n",
      "Also, deep learning models are often end-to-end trainable, meaning they can handle the entire process from input data to output without manual feature extraction. This is in contrast to older approaches where features were engineered manually before feeding into a model.\n",
      "\n",
      "I should make sure I'm not confusing deep learning with other machine learning techniques like support vector machines or decision trees. Those are different because they don't typically use layered architectures for their core algorithms.\n",
      "\n",
      "So, in summary, my understanding is that deep learning uses multi-layered neural networks to learn complex patterns from data, enabling tasks like image and speech recognition by capturing hierarchical features automatically.\n",
      "</think>\n",
      "\n",
      "Deep learning is a subset of machine learning that utilizes multi-layered artificial neural networks to model and recognize complex patterns in data. These networks, known as deep neural networks, consist of several layers (hence \"deep\"), allowing them to learn hierarchical representations from raw input data. This approach enables tasks such as image recognition, speech processing, and natural language understanding by capturing intricate features at each layer.\n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1. **Definition**: Deep learning involves training artificial neural networks with many layers to model hierarchical patterns in data.\n",
      "2. **Layers in Neural Networks**: Each layer processes information from the previous one, starting from simple features (e.g., edges in images) and building up to more complex ones (e.g., object recognition).\n",
      "3. **Applications**: It is used for tasks like image classification, speech recognition, and text analysis, where it outperforms traditional machine learning methods due to its ability to learn abstract features automatically.\n",
      "4. **Advantages**: Requires large datasets, leverages computational power, and uses algorithms like backpropagation for weight optimization, allowing end-to-end training without manual feature engineering.\n",
      "\n",
      "In essence, deep learning excels in handling complex data by simulating the human brain's layered neural structure, enabling sophisticated pattern recognition and decision-making processes.\n",
      "ValueError occurred: Could not parse LLM output: `<think>\n",
      "Okay, so I need to figure out what deep learning is. Hmm, I've heard the term before in tech and machine learning contexts, but I'm not entirely sure about the details. Let me start by breaking down the word itself. \"Deep\" usually implies something complex or multi-layered, and \"learning\" suggests some kind of training or process.\n",
      "\n",
      "I remember that deep learning is a subset of machine learning, which is part of artificial intelligence. So maybe it's a type of AI that uses algorithms inspired by neural networks. Neural networks in the human brain have layers—like neurons connected in multiple layers—and perhaps deep learning refers to having many such layers in machines as well.\n",
      "\n",
      "Wait, I think \"deep\" here refers to having several layers of neurons or artificial neurons. Traditional machine learning models might use a few layers, but deep learning uses many more, allowing them to learn more complex patterns from data. So maybe it's about using these multi-layered neural networks for tasks like image recognition or natural language processing.\n",
      "\n",
      "Let me think of examples where deep learning is applied. I've heard terms like convolutional neural networks (CNNs) used in image analysis and recurrent neural networks (RNNs) for sequence data like text. These seem to be types of deep learning models because they have multiple layers.\n",
      "\n",
      "So, putting it together: deep learning involves training artificial neural networks with many layers to learn hierarchical representations of data. This allows the model to capture complex patterns and perform tasks that are difficult with traditional machine learning approaches.\n",
      "\n",
      "I should also consider the process involved in deep learning. It typically requires a lot of data, computational power because each layer processes information, and algorithms like backpropagation to adjust weights based on errors. The result is systems that can automate decision-making or pattern recognition beyond what's possible with simpler models.\n",
      "\n",
      "Wait, but I'm not entirely clear on why having multiple layers is crucial. Does it help in learning more abstract features? For instance, in image classification, the first layer might detect edges, the next layer shapes, then textures, and so on, up to recognizing objects. So each layer builds upon the previous one's features.\n",
      "\n",
      "Also, deep learning models are often end-to-end trainable, meaning they can handle the entire process from input data to output without manual feature extraction. This is in contrast to older approaches where features were engineered manually before feeding into a model.\n",
      "\n",
      "I should make sure I'm not confusing deep learning with other machine learning techniques like support vector machines or decision trees. Those are different because they don't typically use layered architectures for their core algorithms.\n",
      "\n",
      "So, in summary, my understanding is that deep learning uses multi-layered neural networks to learn complex patterns from data, enabling tasks like image and speech recognition by capturing hierarchical features automatically.\n",
      "</think>\n",
      "\n",
      "Deep learning is a subset of machine learning that utilizes multi-layered artificial neural networks to model and recognize complex patterns in data. These networks, known as deep neural networks, consist of several layers (hence \"deep\"), allowing them to learn hierarchical representations from raw input data. This approach enables tasks such as image recognition, speech processing, and natural language understanding by capturing intricate features at each layer.\n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1. **Definition**: Deep learning involves training artificial neural networks with many layers to model hierarchical patterns in data.\n",
      "2. **Layers in Neural Networks**: Each layer processes information from the previous one, starting from simple features (e.g., edges in images) and building up to more complex ones (e.g., object recognition).\n",
      "3. **Applications**: It is used for tasks like image classification, speech recognition, and text analysis, where it outperforms traditional machine learning methods due to its ability to learn abstract features automatically.\n",
      "4. **Advantages**: Requires large datasets, leverages computational power, and uses algorithms like backpropagation for weight optimization, allowing end-to-end training without manual feature engineering.\n",
      "\n",
      "In essence, deep learning excels in handling complex data by simulating the human brain's layered neural structure, enabling sophisticated pattern recognition and decision-making processes.`\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import Ollama\n",
    "from langchain.agents import initialize_agent, AgentType, AgentOutputParser\n",
    "from langchain.tools import Tool\n",
    "import re\n",
    "\n",
    "# Custom Output Parser to handle responses\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, text):\n",
    "        print(\"LLM Output:\", text)  # Debugging: To see what the LLM returns\n",
    "        if \"Final Answer:\" in text:\n",
    "            final_answer = text.split(\"Final Answer:\")[-1].strip()\n",
    "            return {\"output\": final_answer}  # Return final answer directly\n",
    "        raise ValueError(f\"Could not parse LLM output: `{text}`\")  # Raise error if format doesn't match\n",
    "\n",
    "# Initialize Wikipedia tool\n",
    "wiki_api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n",
    "\n",
    "# Initialize Arxiv tool\n",
    "arxiv_api_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_api_wrapper)\n",
    "\n",
    "# Initialize the Ollama LLM\n",
    "llm = Ollama(model=\"deepseek-r1\")\n",
    "\n",
    "# Define a custom prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are an AI assistant. Use the following format to answer the question:\n",
    "Thought: Explain your reasoning.\n",
    "Action: Specify the tool you will use (if any).\n",
    "Action Input: Provide input for the tool (if any).\n",
    "Final Answer: Provide the final response.\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate object\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "\n",
    "# Define tools for the agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Wikipedia\",\n",
    "        func=wiki.run,\n",
    "        description=\"Use this tool to search information on Wikipedia.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Arxiv\",\n",
    "        func=arxiv.run,\n",
    "        description=\"Use this tool to search academic papers on Arxiv.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize the agent with tools and LLM using the custom prompt and output parser\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\"output_parser\": CustomOutputParser()},  # Now passing as valid instance\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Define the query\n",
    "query = \"What is deep learning?\"\n",
    "\n",
    "# Run the agent with only the query\n",
    "try:\n",
    "    response = agent.run(query)  # Pass only the query string, not a dictionary\n",
    "    print(\"Agent Response:\", response)\n",
    "except AttributeError as e:\n",
    "    print(f\"AttributeError occurred: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\STA\\AppData\\Local\\Temp\\ipykernel_8964\\2951367335.py:17: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  vectordb = FAISS.from_documents(documents, OllamaEmbeddings(model=\"deepseek-r1\"))  # Use deepseek-r1 here\n",
      "C:\\Users\\STA\\AppData\\Local\\Temp\\ipykernel_8964\\2951367335.py:49: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `<think>\nOkay, so I need to figure out what \"math\" refers to in this context. The user mentioned that I have access to Wikipedia, Arxiv, and a Retrieval tool. Hmm, first off, when someone says \"the math,\" it's a bit vague because it can refer to mathematics in general or specific instances like mathematical formulas, mathematicians, or even something like the \"math\" used in everyday language, maybe referencing numerals.\n\nSince I don't have prior knowledge of what they're asking for beyond this specific question, I should probably start by looking up some basic information about mathematics. That makes sense because if it's a general term, knowing its basics would help clarify any confusion.\n\nSo, the first step is to use Wikipedia to get an overview. I'll query \"Mathematics\" on Wikipedia. The summary says math is the study of quantity, structure, space, and change. It's used as a tool in various fields like natural science, engineering, medicine, and economics. That gives me a basic understanding.\n\nNow that I know it's about numbers, structures, and patterns, maybe \"the math\" refers to something specific, but without more context, it's hard to tell. Perhaps the user is asking for an introduction or definitions of different areas within mathematics, like algebra or calculus? Or maybe they're referring to mathematical concepts in a particular context, such as statistics?\n\nI should check if there are any other relevant sources available through Arxiv. Maybe there are recent papers on foundational math topics. But given that I don't have access to the internet, I can only use these tools as provided.\n\nAlternatively, perhaps using the Retrieval tool could help me get more precise information based on some keywords related to \"math.\" But without knowing exactly what they need, it's tricky. Maybe they just want a summary or an overview of mathematics.\n\nGiven that, I think providing the general definition from Wikipedia is a good start. If more details are needed, further actions can be taken, but for now, this seems like the best initial step to understand \"the math.\"\n</think>\n\nThe term \"math\" generally refers to mathematics, which is the study of numbers, structures, patterns, and change. It serves as a fundamental tool across various disciplines including natural sciences, engineering, medicine, and economics. This broad field encompasses different branches such as algebra, calculus, geometry, and statistics.\n\n**Answer:**  \nMathematics is the systematic study of quantity, structure, space, and change, providing a foundational framework for understanding patterns and relationships in various scientific and practical contexts.`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1358\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1358\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m   1359\u001b[0m         intermediate_steps,\n\u001b[0;32m   1360\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1361\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1362\u001b[0m     )\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:805\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py:79\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL):\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[0;32m     82\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m     83\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     84\u001b[0m     )\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[0;32m     87\u001b[0m ):\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: `<think>\nOkay, so I need to figure out what \"math\" refers to in this context. The user mentioned that I have access to Wikipedia, Arxiv, and a Retrieval tool. Hmm, first off, when someone says \"the math,\" it's a bit vague because it can refer to mathematics in general or specific instances like mathematical formulas, mathematicians, or even something like the \"math\" used in everyday language, maybe referencing numerals.\n\nSince I don't have prior knowledge of what they're asking for beyond this specific question, I should probably start by looking up some basic information about mathematics. That makes sense because if it's a general term, knowing its basics would help clarify any confusion.\n\nSo, the first step is to use Wikipedia to get an overview. I'll query \"Mathematics\" on Wikipedia. The summary says math is the study of quantity, structure, space, and change. It's used as a tool in various fields like natural science, engineering, medicine, and economics. That gives me a basic understanding.\n\nNow that I know it's about numbers, structures, and patterns, maybe \"the math\" refers to something specific, but without more context, it's hard to tell. Perhaps the user is asking for an introduction or definitions of different areas within mathematics, like algebra or calculus? Or maybe they're referring to mathematical concepts in a particular context, such as statistics?\n\nI should check if there are any other relevant sources available through Arxiv. Maybe there are recent papers on foundational math topics. But given that I don't have access to the internet, I can only use these tools as provided.\n\nAlternatively, perhaps using the Retrieval tool could help me get more precise information based on some keywords related to \"math.\" But without knowing exactly what they need, it's tricky. Maybe they just want a summary or an overview of mathematics.\n\nGiven that, I think providing the general definition from Wikipedia is a good start. If more details are needed, further actions can be taken, but for now, this seems like the best initial step to understand \"the math.\"\n</think>\n\nThe term \"math\" generally refers to mathematics, which is the study of numbers, structures, patterns, and change. It serves as a fundamental tool across various disciplines including natural sciences, engineering, medicine, and economics. This broad field encompasses different branches such as algebra, calculus, geometry, and statistics.\n\n**Answer:**  \nMathematics is the systematic study of quantity, structure, space, and change, providing a foundational framework for understanding patterns and relationships in various scientific and practical contexts.`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 96\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Run the agent with a query\u001b[39;00m\n\u001b[0;32m     95\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the math?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 96\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Print the response\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\chains\\base.py:606\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1624\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1624\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1633\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1634\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1330\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1323\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1330\u001b[0m         [\n\u001b[0;32m   1331\u001b[0m             a\n\u001b[0;32m   1332\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1333\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1334\u001b[0m                 color_mapping,\n\u001b[0;32m   1335\u001b[0m                 inputs,\n\u001b[0;32m   1336\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1337\u001b[0m                 run_manager,\n\u001b[0;32m   1338\u001b[0m             )\n\u001b[0;32m   1339\u001b[0m         ]\n\u001b[0;32m   1340\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1330\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1323\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1330\u001b[0m         [\n\u001b[0;32m   1331\u001b[0m             a\n\u001b[0;32m   1332\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1333\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1334\u001b[0m                 color_mapping,\n\u001b[0;32m   1335\u001b[0m                 inputs,\n\u001b[0;32m   1336\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1337\u001b[0m                 run_manager,\n\u001b[0;32m   1338\u001b[0m             )\n\u001b[0;32m   1339\u001b[0m         ]\n\u001b[0;32m   1340\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\STA\\Desktop\\LangChain\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1369\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m-> 1369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1370\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn output parsing error occurred. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m     )\n\u001b[0;32m   1375\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `<think>\nOkay, so I need to figure out what \"math\" refers to in this context. The user mentioned that I have access to Wikipedia, Arxiv, and a Retrieval tool. Hmm, first off, when someone says \"the math,\" it's a bit vague because it can refer to mathematics in general or specific instances like mathematical formulas, mathematicians, or even something like the \"math\" used in everyday language, maybe referencing numerals.\n\nSince I don't have prior knowledge of what they're asking for beyond this specific question, I should probably start by looking up some basic information about mathematics. That makes sense because if it's a general term, knowing its basics would help clarify any confusion.\n\nSo, the first step is to use Wikipedia to get an overview. I'll query \"Mathematics\" on Wikipedia. The summary says math is the study of quantity, structure, space, and change. It's used as a tool in various fields like natural science, engineering, medicine, and economics. That gives me a basic understanding.\n\nNow that I know it's about numbers, structures, and patterns, maybe \"the math\" refers to something specific, but without more context, it's hard to tell. Perhaps the user is asking for an introduction or definitions of different areas within mathematics, like algebra or calculus? Or maybe they're referring to mathematical concepts in a particular context, such as statistics?\n\nI should check if there are any other relevant sources available through Arxiv. Maybe there are recent papers on foundational math topics. But given that I don't have access to the internet, I can only use these tools as provided.\n\nAlternatively, perhaps using the Retrieval tool could help me get more precise information based on some keywords related to \"math.\" But without knowing exactly what they need, it's tricky. Maybe they just want a summary or an overview of mathematics.\n\nGiven that, I think providing the general definition from Wikipedia is a good start. If more details are needed, further actions can be taken, but for now, this seems like the best initial step to understand \"the math.\"\n</think>\n\nThe term \"math\" generally refers to mathematics, which is the study of numbers, structures, patterns, and change. It serves as a fundamental tool across various disciplines including natural sciences, engineering, medicine, and economics. This broad field encompasses different branches such as algebra, calculus, geometry, and statistics.\n\n**Answer:**  \nMathematics is the systematic study of quantity, structure, space, and change, providing a foundational framework for understanding patterns and relationships in various scientific and practical contexts.`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Wikipedia tool setup\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Web scraping and vectorization setup\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vectordb = FAISS.from_documents(documents, OllamaEmbeddings(model=\"deepseek-r1\"))  # Use deepseek-r1 here\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "# Create retriever tool\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever, \"langsmith_search\",\n",
    "                                      \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")\n",
    "\n",
    "# Arxiv Tool setup\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "\n",
    "tools = [wiki, arxiv, retriever_tool]\n",
    "\n",
    "# Load the deepseek-r1 model using Ollama\n",
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"deepseek-r1\")  # Change to deepseek-r1\n",
    "\n",
    "# LangChain LLMChain setup with custom prompt template\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define a custom prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the following question: {question}\"\n",
    ")\n",
    "\n",
    "# Create LangChain LLMChain using the deepseek-r1 model\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Run the chain with a question\n",
    "response = chain.run(\"What is deep learning?\")\n",
    "#print(response)\n",
    "\n",
    "# Initialize the agent with the deepseek-r1 model\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "\n",
    "# Define your tools\n",
    "wiki = Tool(\n",
    "    name=\"Wikipedia\",\n",
    "    func=WikipediaAPIWrapper().run,\n",
    "    description=\"Useful for searching information on Wikipedia.\"\n",
    ")\n",
    "\n",
    "arxiv = Tool(\n",
    "    name=\"Arxiv\",\n",
    "    func=ArxivAPIWrapper().run,\n",
    "    description=\"Useful for searching academic papers on Arxiv.\"\n",
    ")\n",
    "\n",
    "# Custom retriever tool\n",
    "def retriever_tool(query: str) -> str:\n",
    "    return f\"Retrieved information for: {query}\"\n",
    "\n",
    "retriever = Tool(\n",
    "    name=\"Retriever\",\n",
    "    func=retriever_tool,\n",
    "    description=\"Useful for retrieving custom information.\"\n",
    ")\n",
    "\n",
    "# List of tools\n",
    "tools = [wiki, arxiv, retriever]\n",
    "\n",
    "# Initialize the agent with the deepseek-r1 model\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # Specify the agent type\n",
    "    verbose=True  # Optional: Set to True to see intermediate steps\n",
    ")\n",
    "\n",
    "# Run the agent with a query\n",
    "query = \"What is the math?\"\n",
    "response = agent.run(query)\n",
    "\n",
    "# Print the response\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\STA\\AppData\\Local\\Temp\\ipykernel_21188\\1122618826.py:22: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  vectordb = FAISS.from_documents(documents, OllamaEmbeddings(model=\"deepseek-r1\"))\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# List of websites to scrape\n",
    "urls = [\n",
    "    \"https://www.zoopla.co.uk/discover/buying/answers-to-your-most-common-mortgage-questions/\",\n",
    "    \"https://moneysavingguru.co.uk/info/what-will-a-mortgage-advisor-ask-me/\"\n",
    "]\n",
    "\n",
    "# Web scraping setup\n",
    "docs = []\n",
    "for url in urls:\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "# Text splitting\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "# Embedding and vector store\n",
    "vectordb = FAISS.from_documents(documents, OllamaEmbeddings(model=\"deepseek-r1\"))\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "# Now, you can use retriever to search for mortgage-related information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An experienced mortgage advisor will guide you through the pros and cons of each major product type to help identify your best fit. \n",
      "Their role is to find you a mortgage that’s not just affordable today but over the full loan term.\n",
      "7. Do You Have Children or Plans to Start a Family?\n",
      "Your family situations or plans matter.\n",
      "If you already have kids, be honest about any childcare, education or maintenance costs.\n",
      "And if you’re looking to have children soon, then your lender will factor the potential loss of income (e.g. paternity/maternity leave) and higher family spending into their calculations.\n",
      "While starting a family is an exciting time, mortgage lenders must ensure your loan remains affordable even with the added costs that children bring. \n",
      "Openly discussing your family plans allows them to properly “stress test” affordability over the long mortgage term.\n",
      "9. What Are Your Potential Long-Term Housing Plans?\n",
      "Credit cards\n",
      "Personal loans\n",
      "Hire purchase agreements\n",
      "Court judgements/decrees\n",
      "Debt management plans\n",
      "\n",
      "Having some existing borrowing is usually okay, provided you can evidence a good, consistent repayment history over 12-24 months. \n",
      "Lenders are wary of approving mortgages if your existing debts are so high that adding mortgage payments would strain your finances too much.\n",
      "4. Where Is Your Deposit Coming From?\n",
      "If your deposit has been diligently saved from your income over time, provide statements showing the buildup of funds. \n",
      "Deposits can also come from:\n",
      "\n",
      "Gifts from family (with a gift letter)\n",
      "An inheritance (with legal documentation)\n",
      "The sale of another property (with proof of sale and funds transfer)\n",
      "Whatever the source, be transparent with your lender and provide any valid proof you have. The clearer your deposit’s paper trail, the smoother your mortgage approval will be.\n",
      "5. What Is Your Current Employment Situation?\n",
      "How you earn a living heavily influences what mortgage deals and loan amounts you’ll qualify for.\n",
      "For employed applicants, state your job title, whether you’re in a permanent or contract/temporary role, time at your employer and any foreseeable changes coming up like job moves or promotions. \n",
      "Being able to showcase a continuous, stable employment history strengthens your mortgage application.\n",
      "If you’re self-employed, have around 2-3 years’ worth of accounts, tax returns and income projections prepared. \n",
      "More complex income structures like temporary/agency workers, zero-hours contracts or those with heavy bonus/commission elements will face deeper questioning to satisfy lenders on income sustainability.\n",
      "6. What Type of Mortgage Product Suits You Best?\n",
      "There may be a fee for mortgage advice only if you decide to proceed. If you are thinking of consolidating existing borrowing you should be aware that you may be extending the terms of the debt and increasing the total amount you repay. The exact savings you could make from remortgaging will vary depending on your circumstances. Nothing on this website constitutes financial advice. However, we do look to match you with the right financial advice so you can speak to a qualified financial advisor.\n"
     ]
    }
   ],
   "source": [
    "# Ask a question to retrieve information related to mortgages\n",
    "query = \"What are the main types of mortgages available in the UK?\"\n",
    "\n",
    "# Use the retriever to search for information\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print only the page_content\n",
    "for doc in results:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader, PDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Step 1: Define the web scraping and PDF data loading (Mortgage-specific content)\n",
    "urls = [\n",
    "    \"https://www.zoopla.co.uk/discover/buying/answers-to-your-most-common-mortgage-questions/\",\n",
    "    \"https://moneysavingguru.co.uk/info/what-will-a-mortgage-advisor-ask-me/\"\n",
    "]\n",
    "\n",
    "# Load PDF file data\n",
    "pdf_loader = PDFLoader(\"/mnt/data/AI Mortgage Advisor Project.pdf\")\n",
    "pdf_docs = pdf_loader.load()\n",
    "\n",
    "# Scraping data from the websites\n",
    "docs = []\n",
    "for url in urls:\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "# Combine web scraped data and PDF data\n",
    "all_docs = docs + pdf_docs\n",
    "\n",
    "# Step 2: Split the documents into chunks using RecursiveCharacterTextSplitter\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(all_docs)\n",
    "\n",
    "# Step 3: Use Ollama Embeddings to convert documents into vectors\n",
    "vectordb = FAISS.from_documents(documents, OllamaEmbeddings(model=\"deepseek-r1\"))\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "# Define a custom retriever tool to fetch mortgage-related info\n",
    "def retriever_tool(query: str) -> str:\n",
    "    return f\"Retrieved mortgage-related information for: {query}\"\n",
    "\n",
    "retriever_tool = Tool(\n",
    "    name=\"Mortgage Information Retriever\",\n",
    "    func=retriever_tool,\n",
    "    description=\"Useful for retrieving mortgage-related information.\"\n",
    ")\n",
    "\n",
    "# Step 4: Set up the LLM chain for personalized responses based on user inputs\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Define the prompt template for personalized mortgage responses\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"user_name\", \"purpose\", \"credit_score\", \"loan_amount\", \"loan_term\", \"interest_rate\", \"down_payment\"],\n",
    "    template=\"\"\"\n",
    "    Here is a summary for {user_name} regarding their mortgage inquiry:\n",
    "    - Purpose: {purpose}\n",
    "    - Credit Score: {credit_score}\n",
    "    - Estimated Loan Amount: {loan_amount}\n",
    "    - Loan Term: {loan_term} years\n",
    "    - Interest Rate: {interest_rate}\n",
    "    - Down Payment: {down_payment}\n",
    "    \n",
    "    Based on this information, please provide a personalized recommendation from the available mortgage options.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create LLMChain using GPT-4 and the defined summary prompt\n",
    "llm_summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "\n",
    "# Step 5: Initialize the agent for interactive conversation\n",
    "agent = initialize_agent(\n",
    "    tools=[retriever_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Step 6: Define a function to handle mortgage-related user queries\n",
    "def handle_mortgage_query(user_query):\n",
    "    # Check if the query contains mortgage-related keywords\n",
    "    mortgage_keywords = ['mortgage', 'loan', 'interest rate', 'down payment', 'credit score', 'repayment', 'refinance']\n",
    "    \n",
    "    # If the question is mortgage-related, use the retriever to fetch information\n",
    "    if any(keyword in user_query.lower() for keyword in mortgage_keywords):\n",
    "        return agent.run(user_query)\n",
    "    else:\n",
    "        # If the question is not mortgage-related, return a polite response\n",
    "        return \"I can only assist with mortgage-related queries.\"\n",
    "\n",
    "# Step 7: Example use case - Mortgage-related user interaction\n",
    "print(\"Welcome to our mortgage assistant service! I’m here to help with your mortgage questions.\")\n",
    "user_name = input(\"May I know your name to make this conversation more personal? \")\n",
    "\n",
    "# Example questions to user\n",
    "print(f\"Hello {user_name}, let’s get started! What is the purpose of your mortgage?\")\n",
    "purpose = input(\"Your response: \")\n",
    "\n",
    "print(\"Got it! Now, could you share your credit score range? (e.g., Excellent, Good, Fair)\")\n",
    "credit_score = input(\"Your response: \")\n",
    "\n",
    "print(\"What’s your estimated budget or loan amount?\")\n",
    "loan_amount = input(\"Your response: \")\n",
    "\n",
    "print(\"How long do you plan to take the loan for? (15, 20, 30 years)\")\n",
    "loan_term = input(\"Your response: \")\n",
    "\n",
    "print(\"Do you prefer a fixed or adjustable interest rate?\")\n",
    "interest_rate = input(\"Your response: \")\n",
    "\n",
    "print(\"How much down payment can you afford?\")\n",
    "down_payment = input(\"Your response: \")\n",
    "\n",
    "# Step 8: Generate the personalized summary using LLMChain\n",
    "generated_summary = llm_summary_chain.run(\n",
    "    user_name=user_name,\n",
    "    purpose=purpose,\n",
    "    credit_score=credit_score,\n",
    "    loan_amount=loan_amount,\n",
    "    loan_term=loan_term,\n",
    "    interest_rate=interest_rate,\n",
    "    down_payment=down_payment\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Mortgage Summary:\")\n",
    "print(generated_summary)\n",
    "\n",
    "# Step 9: Ask if the user is interested in this mortgage option\n",
    "interest = input(\"\\nAre you interested in this mortgage option? (Yes/No) \")\n",
    "\n",
    "if interest.lower() == \"yes\":\n",
    "    # Send information to human mortgage advisor\n",
    "    print(\"Thank you! I will now send your details to a human mortgage advisor.\")\n",
    "    # Send the email to the advisor (you will need to implement this functionality as needed)\n",
    "else:\n",
    "    print(\"Thank you for your time. Feel free to reach out if you have more questions!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
